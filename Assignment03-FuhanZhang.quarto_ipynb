{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Assignment 03\n",
        "author:\n",
        "  - name: Fuhan Zhang\n",
        "    affiliations:\n",
        "      - id: U38201998\n",
        "        name: Boston University\n",
        "        city: Boston\n",
        "        state: MA\n",
        "number-sections: true\n",
        "embed-resources: true\n",
        "date: '2025-09-21'\n",
        "format:\n",
        "  html:\n",
        "    toc: true\n",
        "    toc-depth: 2\n",
        "    fig-format: png\n",
        "    code-overflow: wrap\n",
        "  docx: default\n",
        "  pdf: default\n",
        "date-modified: today\n",
        "date-format: long\n",
        "execute:  \n",
        "  echo: true\n",
        "  eval: true\n",
        "  error: false\n",
        "  freeze: auto\n",
        "---"
      ],
      "id": "a3740d9a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```{markdown}\n",
        "GitHub Link: https://github.com/met-ad-688/assignment-03-FuhanZhang8691.git\n",
        "```\n",
        "\n",
        "# Load the Dataset"
      ],
      "id": "ed523c64"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, sys\n",
        "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
        "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable\n",
        "os.environ.pop(\"SPARK_HOME\", None)\n",
        "os.environ.pop(\"SPARK_DIST_CLASSPATH\", None)\n",
        "os.makedirs(\"./output\", exist_ok=True)\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, monotonically_increasing_id\n",
        "from pyspark.sql import functions as F\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.io as pio\n",
        "from IPython.display import Image, display\n",
        "def show_and_save(fig, path, width=950, height=550, scale=2):\n",
        "    png_bytes = fig.to_image(format=\"png\", width=width, height=height, scale=scale)\n",
        "    with open(path, \"wb\") as f:\n",
        "        f.write(png_bytes)\n",
        "    display(Image(png_bytes)) \n",
        "np.random.seed(42)\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.appName(\"LightcastData\").getOrCreate()\n",
        "# Load Data\n",
        "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"multiLine\",\"true\").option(\"escape\", \"\\\"\").csv(\"./data/lightcast_job_postings.csv\")\n",
        "df.createOrReplaceTempView(\"job_postings\")\n",
        "# Show Schema and Sample Data\n",
        "#print(\"---This is Diagnostic check, No need to print it in the final doc---\")\n",
        "df.printSchema() # comment this line when rendering the submission\n",
        "#df.show(5)\n",
        "df = df.withColumn(\"SALARY\", col(\"SALARY\").cast(\"float\")) \\\n",
        "       .withColumn(\"MAX_YEARS_EXPERIENCE\", col(\"MAX_YEARS_EXPERIENCE\").cast(\"float\"))\n",
        "\n",
        "def compute_median(sdf, col_name):\n",
        "    q = sdf.approxQuantile(col_name, [0.5], 0.01)\n",
        "    return q[0] if q else None\n",
        "median_salary = compute_median(df, \"SALARY\")\n",
        "print(\"Median SALARY:\", median_salary)\n",
        "df = df.fillna({\"SALARY\": median_salary})\n",
        "df = df.withColumn(\"Average_Salary\", col(\"SALARY\"))\n",
        "export_cols = [\n",
        "    \"EDUCATION_LEVELS_NAME\",\n",
        "    \"REMOTE_TYPE_NAME\",\n",
        "    \"MAX_YEARS_EXPERIENCE\",\n",
        "    \"Average_Salary\",\n",
        "    \"SALARY\",\n",
        "    \"LOT_V6_SPECIALIZED_OCCUPATION_NAME\",\n",
        "    \"EMPLOYMENT_TYPE_NAME\"\n",
        "]\n",
        "df_selected = df.select(*export_cols)\n",
        "pdf= df_selected.toPandas()\n",
        "pdf.to_csv(\"./output/cleaned_subset.csv\", index=False)\n",
        "print(\"Data Cleaning Complete. Rows Retained:\", len(pdf))"
      ],
      "id": "c39b50df",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Salary Distribution by Employment Type"
      ],
      "id": "14fc2cdc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "import re\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "os.makedirs(\"output\", exist_ok=True)\n",
        "#Data Cleaning & Filtering\n",
        "pdf = df.filter(df[\"SALARY\"] > 0).select(\"EMPLOYMENT_TYPE_NAME\", \"SALARY\").toPandas()\n",
        "pdf[\"EMPLOYMENT_TYPE_NAME\"] = pdf[\"EMPLOYMENT_TYPE_NAME\"].apply(\n",
        "    lambda x: re.sub(r\"[^\\x00-\\x7F]+\", \"\", str(x)) if x is not None else x\n",
        ")\n",
        "median_salaries = pdf.groupby(\"EMPLOYMENT_TYPE_NAME\")[\"SALARY\"].median()\n",
        "sorted_employment_types = median_salaries.sort_values(ascending=False).index\n",
        "pdf[\"EMPLOYMENT_TYPE_NAME\"] = pd.Categorical(\n",
        "    pdf[\"EMPLOYMENT_TYPE_NAME\"], \\\n",
        "    categories=sorted_employment_types, \n",
        "    ordered=True\n",
        ")\n",
        "#Creating the Boxplot\n",
        "fig = px.box(\n",
        "    pdf,\n",
        "    x=\"EMPLOYMENT_TYPE_NAME\",\n",
        "    y=\"SALARY\",\n",
        "    title=\"Salary Distribution by Employment Type\",\n",
        "    color_discrete_sequence=[\"#ffb6c1\", \"#cb1a72ff\", \"#db7093\", \"#c71585\"],\n",
        "    boxmode=\"group\",\n",
        "    points=\"all\"\n",
        ")\n",
        "fig.update_traces(marker=dict(opacity=0.4, size=3), \n",
        "                  line=dict(width=3, color=\"black\"))\n",
        "fig.update_layout(\n",
        "    title=dict(text=\"Salary Distribution by Employment Type\", font=dict(size=30, family=\"Arial\", color=\"black\", weight=\"bold\")),\n",
        "    margin=dict(t=100, b=80, l=80, r=80),\n",
        "    xaxis=dict(\n",
        "        title=dict(text=\"Employment Type\", font=dict(size=24, family=\"Arial\", color=\"black\", weight=\"bold\")),\n",
        "        tickangle=0,\n",
        "        tickfont=dict(size=18, family=\"Arial\", color=\"black\", weight=\"bold\"),\n",
        "        showline=True, linewidth=2, linecolor=\"black\", mirror=True,\n",
        "        showgrid=False,\n",
        "        categoryorder=\"array\",\n",
        "        categoryarray=sorted_employment_types.tolist()\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        title=dict(text=\"Salary (K $)\", font=dict(size=24, family=\"Arial\", color=\"black\", weight=\"bold\")),\n",
        "        tickvals=[0, 50000, 100000, 150000, 200000, 250000, 300000, 350000, 400000, 450000, 500000],\n",
        "        ticktext=[\"0\", \"50K\", \"100K\", \"150K\", \"200K\", \"250K\", \"300K\", \"350K\", \"400K\", \"450K\", \"500K\"],\n",
        "        tickfont=dict(size=18, family=\"Arial\", color=\"black\", weight=\"bold\"),\n",
        "        showline=True, linewidth=2, linecolor=\"black\", mirror=True,\n",
        "        showgrid=True, gridcolor=\"lightgrey\", gridwidth=0.5\n",
        "    ),\n",
        "  font=dict(family=\"Arial\", size=16, color=\"black\"),\n",
        "    boxgap=0.7,\n",
        "    plot_bgcolor=\"white\",\n",
        "    paper_bgcolor=\"white\",\n",
        "    showlegend=False,\n",
        "    height=500,\n",
        "    width=850\n",
        ")\n",
        "show_and_save(fig, \"output/Q1.png\", width=850, height=500, scale=1)"
      ],
      "id": "f39a788c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The box plot shows the salary distribution under different types of employment. From the graph, it can be seen that the sample size of \"Full time (>32 hours)\" is the largest, and has the salary dispersion approaching $500000, indicating a wider range of job positions with salary distribution. In contrast, the sample size for “Part-time (32 hours)” is smaller, the distribution is more concentrated, and the overall level is lower but there are still a few high-paying outliers. “Part-time/full-time” falls between the other two samples, with an overall salary level higher than pure part-time but lower than pure full-time, and there are also a few high-salary outliers. Overall, full-time positions have the highest salary levels and the most significant fluctuations, while part-time positions are more concentrated and lower, and mixed types fall between the two.\n",
        "\n",
        "\n",
        "# Salary Analysis by ONET Occupation Type (Bubble Chart)"
      ],
      "id": "064d1b61"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "import plotly.express as px\n",
        "os.makedirs(\"output\", exist_ok=True)\n",
        "#Spark SQL to Converting\n",
        "salary_analysis = spark.sql(\"\"\"\n",
        "    SELECT\n",
        "        LOT_V6_SPECIALIZED_OCCUPATION_NAME AS ONET_NAME,\n",
        "        PERCENTILE(SALARY, 0.5) AS Median_Salary,\n",
        "        COUNT(*) AS Job_Postings\n",
        "    FROM job_postings\n",
        "    GROUP BY LOT_V6_SPECIALIZED_OCCUPATION_NAME\n",
        "    ORDER BY Job_Postings DESC\n",
        "    LIMIT 10\n",
        "\"\"\")\n",
        "salary_pd = salary_analysis.toPandas()\n",
        "#Creating Bubble Chart\n",
        "fig = px.scatter(\n",
        "    salary_pd,\n",
        "    x=\"ONET_NAME\",\n",
        "    y=\"Median_Salary\",\n",
        "    size=\"Job_Postings\",\n",
        "    title=\"Salary Analysis by ONET Occupation Type (Bubble Chart)\",\n",
        "    labels={\n",
        "        \"ONET_NAME\": \"ONET Occupation\",\n",
        "        \"Median_Salary\": \"Median Salary\",\n",
        "        \"Job_Postings\": \"Number of Job Postings\"\n",
        "    },\n",
        "    hover_name=\"ONET_NAME\",\n",
        "    size_max=60,\n",
        "    width=1000,\n",
        "    height=600,\n",
        "    color=\"Job_Postings\",\n",
        "    color_discrete_sequence=[\"#ffe4e1\", \"#ffb6c1\", \"#ff69b4\", \"#db7093\", \"#c71585\"],\n",
        ")\n",
        "fig.update_layout(\n",
        "    font_family=\"Arial\",\n",
        "    font_size=14,\n",
        "    title_font_size=25,\n",
        "    xaxis_title=\"ONET Occupation\",\n",
        "    yaxis_title=\"Median Salary\",\n",
        "    plot_bgcolor=\"white\",\n",
        "    xaxis=dict(tickangle=-45, showline=True),\n",
        "    yaxis=dict(showline=True),\n",
        "    margin=dict(t=100, b=80, l=80, r=80)\n",
        ")\n",
        "show_and_save(fig, \"output/Q2.png\", width=1000, height=600, scale=2)"
      ],
      "id": "f6ea4f0a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The bubble chart is based on SparkSQL to calculate the \"Median Salary\" and \"Job Postings\" for each ONET profession, and displays the top 10 based on recruitment volume. The results show that Data Analyst has the largest bubble, ranking first, followed by General ERP Analyst/Consultant, Enterprise Architect, Oracle Consultant/Analyst.Also, the demand for data quality analysts and healthcare analysts is relatively small. Besides, it is worth noting that the median salary of the top 10 professions is almost at the same level, which is around about 115k, and the salary difference between professions is much smaller than the difference in recruitment volume, indicating that the market lacks clear differentiation in salary for different positions, and the greater difference is reflected in the scale of job demand.\n",
        "\n",
        "# Salary by Education Level"
      ],
      "id": "e0af09a7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, when, lit, trim, lower, regexp_replace\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "os.makedirs(\"output\", exist_ok=True)\n",
        "#Building Educational Level Groups\n",
        "df = df.withColumn(\"EDU_CLEAN\", lower(trim(col(\"EDUCATION_LEVELS_NAME\"))))\n",
        "df = df.withColumn(\n",
        "    \"EDU_GROUP\",\n",
        "    when(col(\"EDU_CLEAN\").rlike(\"master|mba|msc\"), lit(\"Master's or PhD\"))\n",
        "    .when(col(\"EDU_CLEAN\").rlike(\"phd|doctor|professional\"), lit(\"Master's or PhD\"))\n",
        "    .when(col(\"EDU_CLEAN\").rlike(\"bachelor|associate|ged|high\\\\s*school|no\\\\s*education\"), lit(\"Bachelor's or lower\"))\n",
        "    .otherwise(lit(\"Other\"))\n",
        ")\n",
        "df = df.withColumn(\"MAX_YEARS_EXPERIENCE\", col(\"MAX_YEARS_EXPERIENCE\").cast(\"double\"))\n",
        "df = df.withColumn(\"Average_Salary\",\n",
        "                   regexp_replace(col(\"Average_Salary\"), \"[$,]\", \"\").cast(\"double\"))\n",
        "df_filtered = (\n",
        "    df.filter((col(\"MAX_YEARS_EXPERIENCE\") > 0) & (col(\"Average_Salary\") > 0))\n",
        "      .filter(col(\"EDU_GROUP\").isin(\"Bachelor's or lower\", \"Master's or PhD\"))\n",
        "      .select(\"MAX_YEARS_EXPERIENCE\",\"Average_Salary\",\"EDU_GROUP\",\"LOT_V6_SPECIALIZED_OCCUPATION_NAME\")\n",
        ")\n",
        "df_pd = df_filtered.toPandas()\n",
        "\n",
        "#Creating the Scatter Plot\n",
        "fig1 = px.scatter(\n",
        "    df_pd,\n",
        "    x=\"MAX_YEARS_EXPERIENCE\",\n",
        "    y=\"Average_Salary\",\n",
        "    color=\"EDU_GROUP\",\n",
        "    hover_data=[\"LOT_V6_SPECIALIZED_OCCUPATION_NAME\"],\n",
        "    opacity=0.7,\n",
        "    color_discrete_sequence=[\"#ffb6c1\", \"#cb1a72\"], \n",
        "    title=\"Experience vs Salary by Education Level\"\n",
        ")\n",
        "fig1.update_traces(marker=dict(size=7, line=dict(width=1, color=\"black\")))\n",
        "fig1.update_layout(\n",
        "    plot_bgcolor=\"#f9f9f9\", paper_bgcolor=\"#EFF5DC\",\n",
        "    font=dict(family=\"Segoe UI\", size=14),\n",
        "    title_font=dict(size=22),\n",
        "    xaxis_title=\"Years of Experience\",\n",
        "    yaxis_title=\"Average Salary (USD)\",\n",
        "    legend_title=\"Education Group\",\n",
        "    hoverlabel=dict(bgcolor=\"white\", font_size=13, font_family=\"Arial\"),\n",
        "    xaxis=dict(gridcolor=\"lightgrey\", tickmode=\"linear\", dtick=1),\n",
        "    yaxis=dict(gridcolor=\"lightgrey\"),\n",
        "    margin=dict(t=100, b=80, l=80, r=80)\n",
        ")\n",
        "show_and_save(fig1, \"output/Q3.png\", width=950, height=600, scale=2)"
      ],
      "id": "c640a143",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The scatter plot illustrates the relationship between work experience and average salary for different educational groups. Overall, with the increase of work experience, the salaries of both educational groups show a certain upward trend, but the distribution is relatively scattered. For the \"Master's or PhD\" group, their average salary is generally higher than that of the \"Bachelor's or Lower\" group, and their advantage is more obvious. At the same time, it can be seen that the high educated population appears more frequently in the high salary range of over $200000, while the low educated population is mostly concentrated in the middle and low salary range, which is between $50000 and $150000. It can be seen that higher education not only brings higher starting salaries in career development, but may also further widen the income gap after accumulating experience.\n",
        "\n",
        "# Salary by Remote Work Type"
      ],
      "id": "5ad0f788"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql.functions import when, trim\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "os.makedirs(\"output\", exist_ok=True)\n",
        "np.random.seed(42)\n",
        "\n",
        "#Work Types Data Setting\n",
        "df = df.withColumn(\"REMOTE_GROUP\",\n",
        "    when(trim(col(\"REMOTE_TYPE_NAME\")) == \"Remote\", \"Remote\")\n",
        "    .when(trim(col(\"REMOTE_TYPE_NAME\")) == \"Hybrid Remote\", \"Hybrid\")\n",
        "    .when(trim(col(\"REMOTE_TYPE_NAME\")) == \"Not Remote\", \"Onsite\")\n",
        "    .when(col(\"REMOTE_TYPE_NAME\").isNull(), \"Onsite\")\n",
        "    .otherwise(\"Onsite\")\n",
        ")\n",
        "df = df.filter(\n",
        "    (col(\"MAX_YEARS_EXPERIENCE\").isNotNull()) &\n",
        "    (col(\"Average_Salary\").isNotNull()) &\n",
        "    (col(\"MAX_YEARS_EXPERIENCE\") > 0) &\n",
        "    (col(\"Average_Salary\") > 0)\n",
        ")\n",
        "df_pd = df.select(\n",
        "    \"MAX_YEARS_EXPERIENCE\", \n",
        "    \"Average_Salary\", \n",
        "    \"LOT_V6_SPECIALIZED_OCCUPATION_NAME\", \n",
        "    \"REMOTE_GROUP\"\n",
        ").toPandas()\n",
        "#Mathematical Adjusting\n",
        "df_pd[\"MAX_EXPERIENCE_JITTER\"] = df_pd[\"MAX_YEARS_EXPERIENCE\"] + np.random.uniform(-0.25, 0.25, size=len(df_pd))\n",
        "df_pd[\"AVERAGE_SALARY_JITTER\"] = df_pd[\"Average_Salary\"] + np.random.uniform(-2500, 2500, size=len(df_pd))\n",
        "df_pd = df_pd.round(2)\n",
        "df_pd.head()\n",
        "df_pd = df_pd[df_pd[\"AVERAGE_SALARY_JITTER\"] <= 390000]\n",
        "\n",
        "#Creating the Scatter Plot\n",
        "fig1 = px.scatter(\n",
        "    df_pd,\n",
        "    x=\"MAX_EXPERIENCE_JITTER\",\n",
        "    y=\"AVERAGE_SALARY_JITTER\",\n",
        "    color=\"REMOTE_GROUP\",\n",
        "    hover_data=[\"LOT_V6_SPECIALIZED_OCCUPATION_NAME\"],\n",
        "    title=\"<b>Experience vs Salary by Remote Work Type</b>\",\n",
        "    opacity=0.7,\n",
        "    color_discrete_sequence=[\"#f9acb7\", \"#96d8ee\", \"#f3f39a\"] \n",
        ")\n",
        "\n",
        "fig1.update_traces(marker=dict(size=7, line=dict(width=1, color=\"black\")))\n",
        "\n",
        "fig1.update_layout(\n",
        "    plot_bgcolor=\"#f9f9f9\",\n",
        "    paper_bgcolor=\"#E9EAFF\",\n",
        "    font=dict(family=\"Segoe UI\", size=14),\n",
        "    title_font=dict(size=22),\n",
        "    margin=dict(t=100, b=80, l=80, r=80),\n",
        "    xaxis_title=\"Years of Experience\",\n",
        "    yaxis_title=\"Average Salary (USD)\",\n",
        "    legend_title=\"Remote Work Type\",\n",
        "    hoverlabel=dict(bgcolor=\"white\", font_size=13, font_family=\"Arial\"),\n",
        "    xaxis=dict(\n",
        "        gridcolor=\"lightgrey\",\n",
        "        tickmode=\"linear\",\n",
        "        tick0=1,\n",
        "        dtick=1,\n",
        "        tickangle=0\n",
        "    ),\n",
        "    yaxis=dict(gridcolor=\"lightgrey\"),\n",
        "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-1.02, xanchor=\"right\", x=1)\n",
        ")\n",
        "\n",
        "show_and_save(fig1, \"output/Q4.png\", width=950, height=550, scale=2)"
      ],
      "id": "ddd87d1a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The scatter plot shows the relationship between work experience and average salary for different types of remote work. Overall, the salary distribution of Onsite (pink), Remote (light blue), and Hybrid (light yellow) highly overlaps in most experience ranges, indicating that remote attributes are not the core factor determining salary levels. Among them, Onsite has the largest number of positions and the widest coverage, while Remote and Hybrid have relatively fewer positions. However, in some experience periods, such as 3 and 7 years, higher salary points have emerged. With the increase of work experience, the salaries of the three types of work modes have an overall upward trend, but the differences are limited."
      ],
      "id": "4ce482d8"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "a03venv",
      "language": "python",
      "display_name": "Python (.venv)",
      "path": "/home/ubuntu/.local/share/jupyter/kernels/a03venv"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}